
### ### ### ### ### ### ### ### ### ### ### ###
#### Facetnet_community_detection.R ####
### ### ### ### ### ### ### ### ### ### ### ###

#### Read me ####
# Created by TO Richardson and Adriano Wanderlingh & adjusted by DS to the needs of Daniel Schläppi
# Takes an interaction list as an input, builds a network to provide a continuous measure of workers' social maturity
# and from social maturity creates the nurse and worker community. 

# requires the following:
# https://c4science.ch/source/facet_unil/
# TO Richardson, T Kay, R Braunschweig, OA Journeau, M Rüegg, ... Ant behavioral maturation is mediated by a stochastic transition between two fundamental states. Current Biology 31, 1-8


#### Prerequisites ####
# Set up directories and parameters

# FACENET community partition parameters
m            <- 2   ## how many communities do we want to instruct FACETNET to search for...? Nurses and Foragers so 2?
alpha        <- 0.5 ## used for modulating the `memory` - how much the community structure @ time t influences that at t+1 - only matters when we ask facetnet to pay attention to this...
t_step       <- 0   ## not important
N_ITERATIONS <- 69
DISPLAY_RESULTS <- F   # optional plotting of results from the facet net thingy... 
UPDATE_DATA <- F    ## as far as I can see optional updating of a variety of tables... Maybe not needed... or can maybe be changed and added to an updated metadata table at some point. 

# set directories to match original version of script
DATADIR <- paste("/media",usr, hd, "vital/fc2",sep="/") 
SCRIPTDIR <- paste("/home",usr,"Documents/vital_rscripts_git",sep="/") #does not (yet) work on the mac

# to match with the code below
data_path <- paste0(DATADIR, "/vital_experiment/main_experiment")
# code_path  <- paste0(SCRIPTDIR, "/source_scripts") # already exists due to running main script - if things run it can be deleted
# source(paste(code_path,"/functions_and_parameters_DS.R",sep=""))  # so far I have not seen the use of this functions. Clean() already defined due to running main analysis

FACETNET_DIR <- paste(DATADIR, "facetNet", sep = "/")  ## the Python script is here - can be anywhere, but this must point to it...

# interaction lists (observed)
input_path           <- paste(data_path,"/intermediary_analysis_steps/full_interaction_lists",sep="")
setwd(input_path)  
input_folders        <- list.dirs(recursive=T,path="PreTreatment",full.names=F)
input_folders        <- input_folders[which(input_folders!="")]
input_folders        <- input_folders[which(input_folders!="random")]


## load the file containing the % time each ant spent outside
TaskStats_File <- paste(data_path, "processed_data/individual_behaviour/pre_treatment/network_position_vs_time_outside.dat", sep="/")
TaskStats_all      <- read.table(TaskStats_File , header=T, stringsAsFactors = F)

#where scores are saved
WORKDIR      <- paste(data_path,"Soft_community_scores_duration",sep="/")
to_keep <- c(ls(),"to_keep","network_files","network_file","output_folders","output_folder")

for (input_folder in input_folders){ # input_folder <- input_folders[1]
  print(input_folder)
  setwd(input_path)
  network_files <- list.files(path=paste("PreTreatment/",input_folder,sep=""),full.names=T)
  output_folder <- file.path(WORKDIR, input_folder)
  if (!file.exists(output_folder)){dir.create(output_folder, recursive = TRUE)}
  
  ## file in which queen community is not the same as the one where ants spend least time outside  ###these two lines were adriano specific and can probably be deleted.
  # network_files <- network_files[!grepl("colony07SP_pathogen.small_PreTreatment",network_files)] 
  
  for (network_file in network_files){ # network_file <- network_files[1]
    
    ### re-open the task_groups (where results are saved) as it gets updated at the end of the loop (the loaded version has to be the newest one)
    task_groups    <- read.table(paste(data_path,"original_data/task_groups.txt",sep="/"),header=T,stringsAsFactors = F)
    # Create new columns if they don't exist in 'task_groups'
    if(!"task_group_FACETNET_0.5" %in% names(task_groups)) {task_groups$task_group_FACETNET_0.5 <- NA}
    if(!"Forager_score" %in% names(task_groups)) {task_groups$Forager_score <- NA}
    
    
    ### get file metadata
    root_name          <- gsub("_interactions.txt","",unlist(strsplit(network_file,split="/"))[grepl("interactions",unlist(strsplit(network_file,split="/")))]) # LS: replace grepl("colony", ...) with grepl("interactions")
    Cassette           <- paste(root_name,"_interactions", sep="")
    #components         <- unlist(strsplit(root_name,split="_"))
    colony             <- unlist(strsplit(root_name,split="_"))[1]
    treatment          <- unlist(strsplit(root_name,split="_"))[2]
    #colony_size        <- info[which(info$colony==colony),"colony_size"]
    period             <- "Pre"
    
    print(basename(root_name)) #"\r",
    
    #MAKE A FOLDER PER COLONY
    FACETNET_REP_folder <- file.path(output_folder, paste(root_name,"_FACETNET_iters",sep="")); if (!file.exists(FACETNET_REP_folder)){dir.create(FACETNET_REP_folder)}
    Module_File        <- paste(FACETNET_REP_folder, paste(Cassette,"Modularities.txt",sep="_"), sep="/")
    
    ### get appropriate task_group list, treated list and tag
    tag <- read.table(paste0(data_path, "/original_data/tag_files/", colony, "_", treatment, ".txt") , header=T,stringsAsFactors = F)
    alive <- tag$tag #AW
    colony_task_group  <- task_groups[which(task_groups$colony==colony), c("tag","task_group_prop")];   colony_task_group <- subset(colony_task_group, tag %in% alive)
    queenid            <- as.character(colony_task_group[which(colony_task_group$task_group=="queen"),"tag"])
    TaskStats          <- TaskStats_all[which(TaskStats_all$colony==colony),]
    TaskStats          <- subset(TaskStats, tag %in% alive)
    
    ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### 
    ##### PART 1: re-format the aggregated interactions list for facetnet soft community labelling    #####
    ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###
    
    if (!file.exists("FACETNET_INPUT")){
      # read interactions & #remove dead ants from interactions list
      interactions       <- read.table(network_file,header=T,stringsAsFactors = F)
      interactions <- subset(interactions, Tag1 %in% alive)
      interactions <- subset(interactions, Tag2 %in% alive)
      ## time-aggregated edge list
      #EdgeList              <- aggregate(Box ~ Tag1 + Tag2, FUN=length, data=interactions)  ; colnames(EdgeList)[ncol(EdgeList)] <- "Count"       ## pairwise contact count
      EdgeList              <- aggregate(duration ~ Tag1 + Tag2, FUN=sum, data=interactions)  ; colnames(EdgeList)[ncol(EdgeList)] <- "duration"       ## pairwise contact duration 
      EdgeList$duration <- round(EdgeList$duration)
      
      ## DEFINE INPUT FILE - needs to be formatted for facetnet python to understand ---????? What do adriano and tom mean here? hopefully it is just right as is... 
      FACETNET_INPUT <- paste(FACETNET_REP_folder,"/",Cassette,"interactions_Time-aggregated_network,FACETNET_format.txt",sep="")
      
      ## Export the aggregated edge list
      write.table(EdgeList, file=`FACETNET_INPUT`, row.names=F, col.names = F, quote=F)
    }
    
    ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### 
    #### PART 2: Repeatedly apply facetnet to generate a community partition                           ####
    ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### 
    
    for (ITER in 1:N_ITERATIONS)  {  # ITER <- 1 # the modularity of the found solutions vary quite a bit... so repeat many times & select the highest-modularity solution 
      ## create new subdirectory for community results with m
      FACETNET_REP_OUTPUT_DIR_M <- paste(FACETNET_REP_folder, paste(Cassette,",m=",m,",Iteration=",ITER,sep=""), sep="/"); if (!file.exists(FACETNET_REP_OUTPUT_DIR_M)){dir.create(FACETNET_REP_OUTPUT_DIR_M)}
      ## check if the outputs already exist
      if ( file.exists( paste(FACETNET_REP_OUTPUT_DIR_M, "soft_comm_step_alpha0.5_nw0.csv", sep="/") ))
      {cat(paste("Facetnet output exists for m=",m,"modules, up to iteration #",ITER),"\r")
      }else{cat(paste("Facetnet output missing for m =",m, "modules, iteration #",ITER),"\r")
        
        FACETNET_INPUT_brackers <- paste0("'",FACETNET_INPUT,"'") #make sure the command is not broken
        FACETNET_REP_OUTPUT_DIR_M_brackers <- paste0("'",FACETNET_REP_OUTPUT_DIR_M,"'")
        
        ## construct facetnet command 
        command <- paste("python3", paste(FACETNET_DIR, "facetnet_step.py", sep = "/"),
                         FACETNET_INPUT_brackers,
                         alpha,
                         m,
                         FACETNET_REP_OUTPUT_DIR_M_brackers,
                         t_step,
                         sep = " ")
        ## jump through hoops to extract the modularity which is just printed to the prompt
        OutPut <- system(command, intern=TRUE) 
        
        ## if error, escape the loop & stop
        if ("TRUE" %in% grepl("rror",OutPut)){print("ERROR in OutPut"); break; print(OutPut)
        }else{
          Item       <- grep("modularity",OutPut) ## 
          Modularity <- as.numeric(gsub(" ", "", gsub("\\(","", gsub("\\)","", strsplit(OutPut[Item], "=")[[1]][2]))))  ## extract the modularity from the output
        }
        ## stack modularity for each m
        Modules <- data.frame(colony, treatment,period, ITER, alpha, MODULARITY=Modularity)
        ## check if the modularity for m communities has already been calculated and recorded
        if (file.exists(Module_File)){ 
          Modules_precomputed <- read.table(Module_File, header = T)
          if (!ITER %in% Modules_precomputed$ITER) {write.table (Modules, file=Module_File, row.names=F, col.names=F, quote=F, append=T)  } ## only add a line to the file if m is not already there !m %in% Modules_precomputed$N_modules; DS: I changed this, only add line if this Iteration is not yet there because Modules_precomputed$N_modules is NULL not defined and m is just 2 defined at the start of the script. 
        }else{
          write.table (Modules, file=Module_File, row.names=F, col.names=T, quote=F, append=F)  }  ## if the file doesn't exist, create it
      }
    }##ITER
    
    ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###
    #### PART 3: Find the top-modularity solution & assign biological labels to both communities       ####
    ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###
    
    if (input_folder=="observed") {
      # reduce these files to the current colony, treatment,period
      TaskStats_ColTreatPer <- TaskStats[which(TaskStats$colony==colony & TaskStats$treatment==treatment & tolower(TaskStats$period)==tolower(period) ), c("tag","time_hours","prop_time_outside")]
      
      ## **KEY STAGE** average the % time outside across the 3 hour pre-introduction bins ## IS THIS RIGHT???
      
      TaskStats_ColTreatPer_MEAN <- aggregate(prop_time_outside ~ tag, FUN=mean, na.rm=TRUE, na.action=NULL, TaskStats_ColTreatPer)
      if (nrow(TaskStats_ColTreatPer_MEAN) != nrow(colony_task_group)) {print("ERROR : the number of tags in TaskStats_ColTreatPer_MEAN is different from that in colony_task_group")}
      
      if (file.exists(Module_File)){
        Modules <- read.table(Module_File, header = T)
        ITER    <- Modules$ITER [which.max(Modules$MODULARITY)]
        
        ## load community scores for the top solution 
        FACETNET_REP_OUTPUT_DIR_M <- paste(FACETNET_REP_folder, paste(Cassette,",m=",m,",Iteration=",ITER,sep=""), sep="/")
        ## load the community scores
        Ant_Modules <- read.csv( file = paste(FACETNET_REP_OUTPUT_DIR_M, "soft_comm_step_alpha0.5_nw0.csv", sep="/")); colnames(Ant_Modules)[match("id",colnames(Ant_Modules))] <- "tag"
        
        ## convert continuous -> binary communities
        Ant_Modules$cluster_binary <- apply( Ant_Modules[,c("cluster_0","cluster_1")], 1, function(x) {c(0,1)[which.max(x)]} ) 
        
        ## add the caste information 
        Combined <- merge(x = TaskStats_ColTreatPer_MEAN, y = colony_task_group, by="tag", all =TRUE)
        ## add the scores for the 2 as-yet unlabelled communities to the df containing % time outside
        Combined <- merge(x = Combined,                   y = Ant_Modules,    by="tag", all =TRUE)
        
        ##  Label the foragers using average time spent outside (& maybe also the distance to the queen)
        ClusterMeans <- aggregate(cbind(prop_time_outside) ~ cluster_binary, FUN=mean, na.rm=T, Combined)
        
        ## which community has the lower mean % time outside? --> THE NURSES
        Nurses_by_prop_time_outside <-  ClusterMeans$cluster_binary [which.min(ClusterMeans$prop_time_outside)]
        # ## which community contains the queen? ---> THE NURSES
        # Nurses_by_queen_affiliation <-  Combined$cluster_binary [ which(Combined$task_group=="queen") ]
        # 
        # COMMENTED OUT AS colony07SP_pathogen.small_PreTreatment has disagreement between time spent with queen and time outside
        # ##  check agreement between the 2 diagnosis methods - if they don't agree, we will need to discuss
        # if (Nurses_by_prop_time_outside != Nurses_by_queen_affiliation){
        #   print("PROBLEM: community identification by % time outside DISAGREES with that by queen affiliation")}
        # else{  
        ## the nurse community is the one that spends the least time outside and that includes the queen (assuming the 2 methods agree...)
        NURSE_COMMUNITY   <- ClusterMeans$cluster_binary [ which.min(ClusterMeans$prop_time_outside)]
        FORAGER_COMMUNITY <- ClusterMeans$cluster_binary [ which.max(ClusterMeans$prop_time_outside)]
        
        ## alter the column names in Ant_Modules to reflect task group labels - a continuous score in the range 0-1 for both modules, SUMMING TO 1 ACROSS MODULES!!
        colnames(Combined) [match( paste("cluster_",FORAGER_COMMUNITY,sep=""), colnames(Combined))] <- "Forager_score"
        colnames(Combined) [match( paste("cluster_",NURSE_COMMUNITY,sep=""),   colnames(Combined))] <- "Nurse_score"
        
        ## add categorical versions of the FACETNET scores - just to compare with the original threshold-based task_group:
        Combined$cluster_binary <- NULL
        Combined$task_group_FACETNET_0.5 <- NA
        Combined$task_group_FACETNET_0.5 [which(Combined$Forager_score > Combined$Nurse_score)] <- "forager"
        Combined$task_group_FACETNET_0.5 [which(Combined$Forager_score < Combined$Nurse_score)] <- "nurse"
        Combined$task_group_FACETNET_0.5 [which(Combined$tag == queenid)] <- "queen"
        #}
        
        if(DISPLAY_RESULTS){
          ## tally the agreement between the original and new (facetnet) task labels
          Agreement <- table(Combined$task_group, Combined$task_group_FACETNET_0.5); rownames(Agreement) <- paste("orig", rownames(Agreement),sep="_"); colnames(Agreement) <- paste("facet", colnames(Agreement), sep="_"); print(Agreement)
        }
        
        # Save output to the task_groups file
        Combined$colony <- colony
        
        # Merge by specified columns
        merged_data <- merge(task_groups, Combined[ ,which(names(Combined) %in%  c("colony", "tag", "Forager_score", "task_group_FACETNET_0.5"))],
                             by=c("colony","tag"), all.x=TRUE, suffixes=c("", ".update"))
        
        # Update FACETNET results based on the specific colony
        # !is.na(merged_data$task_group_FACETNET_0.5.update) checks if there is an updated value available for the task_group_FACETNET_0.5 column
        merged_data$task_group_FACETNET_0.5 <- ifelse(merged_data$colony == colony & !is.na(merged_data$task_group_FACETNET_0.5.update), merged_data$task_group_FACETNET_0.5.update, merged_data$task_group_FACETNET_0.5)
        merged_data$Forager_score <- ifelse(merged_data$colony == colony & !is.na(merged_data$Forager_score.update), merged_data$Forager_score.update, merged_data$Forager_score)
        merged_data$Forager_score <- round(merged_data$Forager_score,3)
        merged_data <- merged_data[order(merged_data$colony),]
        
        write.table(merged_data[, names(task_groups)],
                    file=paste(data_path,"original_data/task_groups.txt",sep="/"),
                    append = F, col.names = T, row.names = F, quote = F, sep = "\t")
      }
    }
  }
  clean()
}













##########################################################################################################################################
# DS: Continue updating below.... not touched yet. 

#### DISPLAY RESULTS  ####

if(DISPLAY_RESULTS){
  library(dplyr)
  library(ggplot2)
  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### 
  ####            fetch best modularity values and save output               ####
  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###
  # # Define directory and patterns
  folder_pattern <- "FACETNET_iters"
  file_pattern <- "interactionsModularities.txt"
  data <- NULL
  
  # Get list of folders matching the pattern
  randys <- list.dirs(WORKDIR, full.names = TRUE, recursive = FALSE)
  for(randy in randys){
    folders <- list.dirs(randy, full.names = TRUE, recursive = FALSE)
    folders <- folders[grep(folder_pattern, folders)]
    
    # Read and rbind files together
    data_list <- lapply(folders, function(folder) {
      file_path <- list.files(folder, pattern = file_pattern, full.names = TRUE)
      if(length(file_path) > 0) {
        return(read.table(file_path, header = TRUE, stringsAsFactors = FALSE))
      }
      return(NULL)
    })
    
    data_randy <- do.call(rbind, data_list)
    data_randy$randy <- basename(randy)
    
    data_randy <- data_randy %>%
      group_by(colony) %>%
      filter(MODULARITY == max(MODULARITY)) %>%
      ungroup()
    
    data_randy$randy <- basename(randy)
    
    data <- rbind(data, data_randy)
  }
  
  #save best modularity output
  write.table(data,
              file=paste(data_path,
                         paste0(basename(WORKDIR),"_modularity.txt"),
                         sep="/"),
              append = F, col.names = T, row.names = F, quote = F, sep = "\t")
  
  ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### 
  ##### ##### ##### #####         PLOT results of OBSERVED ONLY           ##### ##### ##### ##### ##### #####
  ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### ##### 
  task_groups_A    <- read.table("/media/cf19810/Seagate Portable Drive/Lasius-Bristol_pathogen_experiment/main_experiment/original_data/task_groups.txt",header=T,stringsAsFactors = F)
  
  size_order      <- c("small","big")
  task_groups_A$size     <- unlist(lapply( task_groups_A$treatment, function(x)  unlist(strsplit(x,split="\\.") )[2]  ))
  task_groups_A$size      <- factor(task_groups_A$size    , levels=size_order   [which(size_order%in%task_groups_A$size )])
  
  # Generate plots of Social Maturity
  ggplot(task_groups_A, aes(x = Forager_score, colour = size)) + 
    #geom_density(alpha = 0.6,size=1.5, adjust=1/1.2) + # 'adjust' changes the smoothing
    geom_line(aes(color=size,group = colony), stat="density", size=1, alpha=0.2, adjust=1/1.2) +
    geom_line(aes(color=size), stat="density", size=2, alpha=1, adjust=1/1.2) +
    geom_vline(aes(xintercept = 0.5), linetype = "dashed",colour="grey20") + 
    geom_vline(aes(xintercept = 1/4), linetype = "dashed",colour="grey20") + 
    #facet_wrap(~ colony, scales = "free") +
    theme_minimal() +
    xlab("Social maturity (duration contacts)")
  
  ## CHECK WHEN THE BEST MODULARITY VALUE IS ACHIEVED
  
  data_obs <- data[which(data$randy=="observed"),]
  
  # Identify and rank the top modularity values for each colony
  threshold <- 0.95
  
  data_ranked <- data_obs %>%
    group_by(colony) %>%
    mutate(max_modularity = max(MODULARITY),
           is_top = ifelse(MODULARITY >= max_modularity * threshold, 1, 0)) %>%
    filter(is_top == 1) %>%
    mutate(rank = dense_rank(desc(MODULARITY)))
  
  # Count occurrences of each ITER for each rank
  iter_counts <- data_ranked %>%
    group_by(ITER, rank) %>%
    tally()
  
  # Dynamically generate breaks and labels for ranks
  max_rank <- max(iter_counts$rank)
  all_labels <- c("Best", "Second Best", "Third", "Fourth", "Fifth")  # Extend this list if more ranks are expected
  breaks_ranks <- 1:max_rank
  labels_ranks <- all_labels[1:max_rank]
  
  # Check if any NA labels and remove them
  valid_indices <- !is.na(labels_ranks)
  breaks_ranks <- breaks_ranks[valid_indices]
  labels_ranks <- labels_ranks[valid_indices]
  
  iter_counts <- iter_counts[which(iter_counts$rank<=5),]
  
  # Plot
  ggplot(iter_counts, aes(x = factor(ITER), y = n, fill = factor(rank))) +
    geom_bar(stat = "identity") +
    scale_fill_manual(values = colorRampPalette(c("lightblue", "blue"))(max(iter_counts$rank)),
                      name = "Rank",
                      breaks = breaks_ranks,
                      labels = labels_ranks) +
    labs(title = "Distribution of ITER for Top Modularity Ranks",
         x = "ITER",
         y = "Count") +
    theme_minimal()
}






# #Merge cluster output
# # Set the path to the directory
# path <- "/media/cf19810/Seagate Portable Drive/Lasius-Bristol_pathogen_experiment/main_experiment/Soft_community_scores_duration/"
# 
# # List all the text files in the directory
# files <- list.files(path, pattern = "\\.txt$", full.names = TRUE)
# 
# # Read and combine all the files
# combined_data <- do.call(rbind, lapply(files, read.table, header=TRUE, stringsAsFactors=FALSE))
# 
# combined_data$JOBTYPE <- NULL
# combined_data$ITER <- NULL
# combined_data$alpha <- NULL
# # Save the combined data to a new file
# output_path <- "/media/cf19810/Seagate Portable Drive/Lasius-Bristol_pathogen_experiment/main_experiment/Soft_community_scores_duration_1ITER_0.5alpha_full.txt"
# write.table(combined_data, file=output_path, row.names=FALSE, sep="\t", quote=FALSE)
# 









##############

if(UPDATE_DATA){
  #add this info to all the relevant files
  combined_data <- read.table( "/media/cf19810/Seagate Portable Drive/Lasius-Bristol_pathogen_experiment/main_experiment/Soft_community_scores_duration_1ITER_0.5alpha_full.txt", header=TRUE, stringsAsFactors=FALSE)
  combined_data$colony <- paste0("colony",combined_data$colony)
  combined_data$treatment <- paste(combined_data$treatment,combined_data$colony_size,sep=".")
  combined_data$colony_size <- NULL
  combined_data$period <- tolower(gsub("Treatment", "", combined_data$period))
  combined_data$time_hours <- as.numeric(gsub("TH","",combined_data$bin)); combined_data$bin <- NULL
  combined_data$time_of_day <- as.numeric(gsub("TD","",combined_data$TD)); combined_data$TD <- NULL
  combined_data$modularity_FacetNet <- combined_data$MODULARITY; combined_data$MODULARITY <- NULL
  combined_data$randy <- combined_data$ObsRand; combined_data$ObsRand <- NULL
  
  
  outputfolder <- "/media/cf19810/Seagate Portable Drive/Lasius-Bristol_pathogen_experiment/main_experiment/processed_data/network_properties_edge_weights_duration"
  options <- c("all_workers","untreated_only")
  
  for (input_folder in unique(combined_data$randy)){
    
    if (input_folder=="observed"){
      for (option in options) {
        ####Main experiment: write pre_vs_post_treatment data
        outputfolder2 <- paste(outputfolder,"pre_vs_post_treatment",option,sep="/")
        
        summary_collective <- combined_data[which(combined_data$randy=="observed"),]
        
        #append columns for the new efficiency measures #AW mod for task efficiency
        summary_colony_existing <- read.table(paste(outputfolder2,"/colony_data.txt",sep=""),header = T,stringsAsFactors = F)
        common_names <- names(summary_colony_existing)[names(summary_colony_existing) %in% names(summary_collective)]
        summary_colony_existing <- merge(summary_colony_existing, summary_collective, by = common_names, all.x = TRUE)
        
        write.table(summary_colony_existing[,names(summary_colony_existing)!="randy"],file=paste(outputfolder2,"/colony_data.txt",sep=""),col.names = T,row.names=F,append=F,quote=F)
        #write.table(summary_individual[,names(summary_individual)!="randy"],file=paste(outputfolder2,"/individual_data.txt",sep=""),col.names = T,row.names=F,append=F,quote=F)
        
        
        ####All workers: write pre_treatment data into random_vs_observed folder
        if (option=="all_workers"){
          outputfolder3 <- paste(outputfolder,"random_vs_observed",sep="/")
          
          #append columns for the new efficiency measures #AW mod for task efficiency
          summary_colony_existing <- read.table(paste(outputfolder3,"/network_properties_",input_folder,".txt",sep=""),header = T,stringsAsFactors = F)
          common_names <- names(summary_colony_existing)[names(summary_colony_existing) %in% names(summary_collective)]
          summary_colony_existing <- merge(summary_colony_existing, summary_collective, by = common_names, all.x = TRUE)
          
          write.table(summary_colony_existing[which(summary_colony_existing$period=="pre"),],file=paste(outputfolder3,"/network_properties_",input_folder,".txt",sep=""),col.names = T,row.names=F,append=F,quote=F)
          #write.table(summary_individual[which(summary_individual$period=="pre"),],file=paste(outputfolder3,"/node_properties_",input_folder,".txt",sep=""),col.names = T,row.names=F,append=F,quote=F)
          
          outputfolder4 <- paste(outputfolder,"post_treatment",sep="/")
          
          #append columns for the new efficiency measures #AW mod for task efficiency
          summary_colony_existing <- read.table(paste(outputfolder4,"/network_properties_",input_folder,".txt",sep=""),header = T,stringsAsFactors = F)
          common_names <- names(summary_colony_existing)[names(summary_colony_existing) %in% names(summary_collective)]
          summary_colony_existing <- merge(summary_colony_existing, summary_collective, by = common_names, all.x = TRUE)
          
          write.table(summary_colony_existing[which(summary_colony_existing$period=="post"),],file=paste(outputfolder4,"/network_properties_",input_folder,".txt",sep=""),col.names = T,row.names=F,append=F,quote=F)
          #write.table(summary_individual[which(summary_individual$period=="post"),],file=paste(outputfolder4,"/node_properties_",input_folder,".txt",sep=""),col.names = T,row.names=F,append=F,quote=F)
        }
        
      }
      
      #for all not observed
    }else{
      summary_collective <- combined_data[which(combined_data$randy==input_folder),]
      
      outputfolder3 <- paste(outputfolder,"random_vs_observed",sep="/")
      
      #append columns for the new efficiency measures #AW mod for task efficiency
      summary_colony_existing <- read.table(paste(outputfolder3,"/network_properties_",input_folder,".txt",sep=""),header = T,stringsAsFactors = F)
      common_names <- names(summary_colony_existing)[names(summary_colony_existing) %in% names(summary_collective)]
      summary_colony_existing <- merge(summary_colony_existing, summary_collective, by = common_names, all.x = TRUE)
      
      write.table(summary_colony_existing[which(summary_colony_existing$period=="pre"),],file=paste(outputfolder3,"/network_properties_",input_folder,".txt",sep=""),col.names = T,row.names=F,append=F,quote=F)
      #write.table(summary_individual[which(summary_individual$period=="pre"),],file=paste(outputfolder3,"/node_properties_",input_folder,".txt",sep=""),col.names = T,row.names=F,append=F,quote=F)
    }
  }
}